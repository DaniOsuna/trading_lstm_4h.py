{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaLQUxQUpoyUzZVFKh/qyF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaniOsuna/trading_lstm_4h.py/blob/main/trading_lstm_4h_binance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGOgXYPdRaIA"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# SCRIPT MAESTRO - LSTM CLASIFICACIÃ“N EN 4H BINANCE (Paper Trading)\n",
        "################################################################################\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from binance.client import Client   # Para extraer velas 4h\n",
        "\n",
        "#########################\n",
        "# 1) SEED + PARAMETROS\n",
        "#########################\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "BINANCE_API_KEY    = \"e1ZbxHrFw8R3UObyAjRarYkpwtY2kKy9YEPEdrsV0B1Uj8MJFLt0grpUtd0NN04l\"\n",
        "BINANCE_API_SECRET = \"bhnq7RYVVowH0Ov6sDYNCEnU5N5HH4qTa0Z2hChBxJqbwKWIJhBh8cfeS5emekRp\"\n",
        "\n",
        "SYMBOL             = \"BTCUSDT\"\n",
        "INTERVAL           = Client.KLINE_INTERVAL_4HOUR\n",
        "LIMIT_KLINES       = 500   # 4h * 500 = ~ 83 dias\n",
        "\n",
        "THRESHOLD_GAIN     = 0.003   # 0.3%\n",
        "WINDOW             = 30      # 30 velas 4h => 5 dias\n",
        "STOP_LOSS          = 0.02    # 2%\n",
        "TAKE_PROFIT        = 0.03    # 3%\n",
        "COMMISSION         = 0.001   # 0.1% por trade\n",
        "TEST_DAYS          = 180     # 180 velas 4h => 30 dias\n",
        "LR                 = 1e-4\n",
        "BATCH_SIZE         = 32\n",
        "EPOCHS             = 20\n",
        "\n",
        "OUTPUT_CSV         = \"paper_trades_lstm_4h.csv\"\n",
        "\n",
        "#########################\n",
        "# 2) DESCARGAR VELAS 4H\n",
        "#########################\n",
        "def download_klines_4h(symbol, interval, limit):\n",
        "    client = Client(BINANCE_API_KEY, BINANCE_API_SECRET)\n",
        "    klines = client.get_klines(symbol=symbol, interval=interval, limit=limit)\n",
        "    cols = [\"open_time\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\n",
        "            \"close_time\",\"quote_asset_volume\",\"num_trades\",\n",
        "            \"taker_buy_base\",\"taker_buy_quote\",\"ignored\"]\n",
        "    df = pd.DataFrame(klines, columns=cols)\n",
        "    # Index por open_time\n",
        "    df[\"open_time\"] = pd.to_datetime(df[\"open_time\"], unit='ms')\n",
        "    df.set_index(\"open_time\", inplace=True)\n",
        "\n",
        "    # Convertir a float\n",
        "    for c in [\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]:\n",
        "        df[c] = df[c].astype(float)\n",
        "\n",
        "    return df\n",
        "\n",
        "#########################\n",
        "# 3) Weighted BCE\n",
        "#########################\n",
        "def weighted_bce(y_true, y_pred):\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.backend import epsilon\n",
        "    weight_for_1 = 3.0\n",
        "    y_true_f = tf.cast(y_true, tf.float32)\n",
        "    y_pred_f = tf.clip_by_value(y_pred, epsilon(), 1.0 - epsilon())\n",
        "    w0 = 1.0\n",
        "    w1 = weight_for_1\n",
        "    bce = - ( w1*y_true_f*tf.math.log(y_pred_f) + w0*(1.0-y_true_f)*tf.math.log(1.0-y_pred_f) )\n",
        "    return tf.reduce_mean(bce)\n",
        "\n",
        "#########################\n",
        "# 4) BACKTEST BINARIO\n",
        "#########################\n",
        "def backtest_binario(df_test, stop_loss=0.02, take_profit=0.03, commission=0.001):\n",
        "    pnl_list=[]\n",
        "    in_position=False\n",
        "    open_price=None\n",
        "    daily_ret=[]\n",
        "    for i in range(len(df_test)-1):\n",
        "        row= df_test.iloc[i]\n",
        "        if not in_position:\n",
        "            if row['y_pred_bin']==1:\n",
        "                open_price= row['OpenShift']\n",
        "                in_position=True\n",
        "                pnl_list.append(0.0)\n",
        "                daily_ret.append(0.0)\n",
        "            else:\n",
        "                pnl_list.append(0.0)\n",
        "                daily_ret.append(0.0)\n",
        "        else:\n",
        "            current_price= row['OpenShift']\n",
        "            lat_gain= (current_price - open_price)/open_price\n",
        "            close_trade=False\n",
        "            if lat_gain<=-stop_loss: close_trade=True\n",
        "            if lat_gain>=take_profit: close_trade=True\n",
        "            if row['y_pred_bin']==0: close_trade=True\n",
        "            if close_trade:\n",
        "                final_gain= lat_gain - 2*commission\n",
        "                pnl_list.append(final_gain)\n",
        "                daily_ret.append(final_gain)\n",
        "                in_position=False\n",
        "                open_price=None\n",
        "            else:\n",
        "                pnl_list.append(0.0)\n",
        "                daily_ret.append(0.0)\n",
        "    pnl_list.append(0.0)\n",
        "    daily_ret.append(0.0)\n",
        "    df_test['PnL']= pnl_list\n",
        "    df_test['CumPnL']= (1+df_test['PnL']).cumprod()-1\n",
        "    return df_test, daily_ret\n",
        "\n",
        "#########################\n",
        "# 5) METRICAS\n",
        "#########################\n",
        "def calc_metrics(daily_ret):\n",
        "    import pandas as pd\n",
        "    rets= pd.Series(daily_ret)\n",
        "    if len(rets)<1:\n",
        "        return (0,0,0,0)\n",
        "    cumret= (1+ rets).cumprod()-1\n",
        "    peak= cumret.cummax()\n",
        "    dd= (peak-cumret).max()\n",
        "    std_= rets.std()\n",
        "    sharpe= rets.mean()/std_*np.sqrt(365) if std_>1e-9 else 0.0\n",
        "    neg= rets[rets<0]\n",
        "    std_neg= neg.std()\n",
        "    sortino= rets.mean()/ (std_neg+1e-9)*np.sqrt(365) if std_neg>1e-9 else 0.0\n",
        "    gains= rets[rets>0].sum()\n",
        "    losses= abs(rets[rets<0].sum())\n",
        "    pf= (gains/losses) if losses>1e-9 else 999.0\n",
        "    return (sharpe, sortino, dd, pf)\n",
        "\n",
        "#########################\n",
        "# 6) PROCESO PRINCIPAL\n",
        "#########################\n",
        "def main_4h_binance():\n",
        "    print(\"=== INICIO: DESCARGA BINANCE 4H ===\")\n",
        "    df = download_klines_4h(SYMBOL, INTERVAL, LIMIT_KLINES)\n",
        "    print(f\"df shape: {df.shape}\")\n",
        "    print(df.tail(3))\n",
        "\n",
        "    # Calcular Indicadores\n",
        "    df['RSI14'] = ta.rsi(df['Close'], length=14)\n",
        "    macd_ = ta.macd(df['Close'], fast=12, slow=26)\n",
        "    df['MACD']  = macd_['MACD_12_26_9']\n",
        "    df['MACDs'] = macd_['MACDs_12_26_9']\n",
        "    df['EMA7']  = ta.ema(df['Close'], length=7)\n",
        "    df['EMA21'] = ta.ema(df['Close'], length=21)\n",
        "    bb = ta.bbands(df['Close'], length=20)\n",
        "    df['BBU']   = bb['BBU_20_2.0']\n",
        "    df['BBM']   = bb['BBM_20_2.0']\n",
        "    df['BBL']   = bb['BBL_20_2.0']\n",
        "    stochrsi = ta.stochrsi(df['Close'], length=14)\n",
        "    df['STOCHRSIk']= stochrsi['STOCHRSIk_14_14_3_3']\n",
        "    df['STOCHRSId']= stochrsi['STOCHRSId_14_14_3_3']\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # ReturnFut\n",
        "    df['CloseShift'] = df['Close'].shift(-1)\n",
        "    df['ReturnFut']  = (df['CloseShift'] - df['Close']) / df['Close']\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # y_bin => 1 si ReturnFut >= THRESHOLD_GAIN\n",
        "    df['y_bin'] = (df['ReturnFut'] >= THRESHOLD_GAIN).astype(int)\n",
        "\n",
        "    # Separar en train/test\n",
        "    if len(df) < (TEST_DAYS + WINDOW + 5):\n",
        "        print(\"No hay data suficiente para train/test.\")\n",
        "        return\n",
        "\n",
        "    df_train = df.iloc[:-TEST_DAYS].copy()\n",
        "    df_test  = df.iloc[-TEST_DAYS:].copy()\n",
        "\n",
        "    feat_cols = [\n",
        "        \"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"RSI14\",\"MACD\",\"MACDs\",\"EMA7\",\n",
        "        \"EMA21\",\"BBU\",\"BBM\",\"BBL\",\"STOCHRSIk\",\"STOCHRSId\"\n",
        "    ]\n",
        "    df_train.dropna(subset=feat_cols, inplace=True)\n",
        "    df_test.dropna(subset=feat_cols, inplace=True)\n",
        "\n",
        "    from sklearn.preprocessing import RobustScaler\n",
        "    scaler= RobustScaler()\n",
        "    X_train_2D= scaler.fit_transform(df_train[feat_cols].values)\n",
        "    y_train_1D= df_train['y_bin'].values\n",
        "\n",
        "    def create_seq(feat2D, targ1D, w):\n",
        "        X,y=[],[]\n",
        "        for i in range(len(feat2D)-w):\n",
        "            X.append(feat2D[i:i+w])\n",
        "            y.append(targ1D[i+w])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    X_tr, y_tr = create_seq(X_train_2D, y_train_1D, WINDOW)\n",
        "    if len(X_tr) < 10:\n",
        "        print(\"No hay datos de train suficientes.\")\n",
        "        return\n",
        "\n",
        "    # Creamos modelo\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(WINDOW, len(feat_cols))),\n",
        "        Dropout(0.3),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=LR), loss=weighted_bce, metrics=['accuracy'])\n",
        "\n",
        "    val_size = int(len(X_tr)*0.2)\n",
        "    X_trn = X_tr[:-val_size]\n",
        "    y_trn = y_tr[:-val_size]\n",
        "    X_val = X_tr[-val_size:]\n",
        "    y_val = y_tr[-val_size:]\n",
        "\n",
        "    steps_per_epoch = len(X_trn)//BATCH_SIZE\n",
        "    if steps_per_epoch < 1:\n",
        "        print(\"No hay batch para entrenar.\")\n",
        "        return\n",
        "\n",
        "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "    es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "    rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-7)\n",
        "\n",
        "    print(f\"Entrenando con {len(X_trn)} train y {len(X_val)} val.\")\n",
        "    history = model.fit(\n",
        "        X_trn, y_trn,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=[es, rlrop],\n",
        "        shuffle=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Test => mini-backtest\n",
        "    X_test_2D = scaler.transform(df_test[feat_cols].values)\n",
        "    y_test_1D = df_test['y_bin'].values\n",
        "\n",
        "    X_te, y_te = create_seq(X_test_2D, y_test_1D, WINDOW)\n",
        "    if len(X_te)<1:\n",
        "        print(\"Test no genera secuencias.\")\n",
        "        return\n",
        "    df_test_seq = df_test.iloc[WINDOW:].copy()\n",
        "    df_test_seq = df_test_seq.iloc[:len(X_te)]\n",
        "    df_test_seq.reset_index(drop=False, inplace=True)\n",
        "\n",
        "    y_proba_test= model.predict(X_te).flatten()\n",
        "    y_bin_test= (y_proba_test>=0.5).astype(int)\n",
        "    df_test_seq['y_pred_bin']= y_bin_test\n",
        "    df_test_seq['OpenShift']= df_test_seq['Open'].shift(-1)\n",
        "    df_test_seq.dropna(inplace=True)\n",
        "\n",
        "    from statistics import mean, stdev\n",
        "    df_test_seq, daily_ret= backtest_binario(df_test_seq, STOP_LOSS, TAKE_PROFIT, COMMISSION)\n",
        "    final_pnl= df_test_seq['CumPnL'].iloc[-1] * 100\n",
        "\n",
        "    sharpe_t, sortino_t, dd_t, pf_t= calc_metrics(daily_ret)\n",
        "    print(f\"\\n=== MINI-HOLDOUT => {len(df_test_seq)} muestras ===\")\n",
        "    print(f\"PNL= {final_pnl:.2f}%, Sharpe= {sharpe_t:.2f}, Sortino= {sortino_t:.2f}, DD= {dd_t:.2%}, PF= {pf_t:.2f}\")\n",
        "\n",
        "    # SeÃ±al \"live\"\n",
        "    last_block= df.iloc[-WINDOW:].copy()\n",
        "    if len(last_block)< WINDOW:\n",
        "        print(\"No hay data live.\")\n",
        "        return\n",
        "    feat_live= last_block[feat_cols].values\n",
        "    feat_live_scaled= scaler.transform(feat_live)\n",
        "    X_live= np.expand_dims(feat_live_scaled, axis=0)\n",
        "    live_proba= model.predict(X_live).flatten()[0]\n",
        "    live_bin= 1 if live_proba>=0.5 else 0\n",
        "\n",
        "    last_dt= df.index[-1]\n",
        "    signal_str= \"BUY\" if live_bin==1 else \"NO_BUY\"\n",
        "    print(f\"SeÃ±al del dÃ­a => {signal_str} (prob={live_proba:.4f}), ultima vela: {last_dt}\")\n",
        "\n",
        "    # Guardar info de la ejecuciÃ³n\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    row_save= {\n",
        "        \"datetime\": last_dt,\n",
        "        \"live_proba\": live_proba,\n",
        "        \"signal\": signal_str,\n",
        "        \"test_pnl\": final_pnl,\n",
        "        \"test_pf\": pf_t,\n",
        "        \"sharpe_test\": sharpe_t,\n",
        "        \"sortino_test\": sortino_t\n",
        "    }\n",
        "\n",
        "    df_save = pd.DataFrame([row_save])\n",
        "    if os.path.isfile(OUTPUT_CSV):\n",
        "        df_save.to_csv(OUTPUT_CSV, mode='a', header=False, index=False)\n",
        "    else:\n",
        "        df_save.to_csv(OUTPUT_CSV, mode='w', header=True, index=False)\n",
        "\n",
        "    print(f\"\\nGuardado en {OUTPUT_CSV}\")\n",
        "    print(\"=== FIN SCRIPT 4H BINANCE (paper) ===\")\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main_4h_binance()"
      ]
    }
  ]
}